{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jbpgVTtB1Jyg"
   },
   "source": [
    "NOTE: first preprocess the data by running crop_images.py (for CUB-200-2011) and create_modified_datasets.ipynb. The following datastructure is required:\n",
    "\n",
    "The following folders should be present:\n",
    "\n",
    "\t- ProtoPNet/datasets/cub200_cropped/train_cropped\n",
    "\t- ProtoPNet/datasets/cub200_cropped/train_cropped_contrast\n",
    "\t- ProtoPNet/datasets/cub200_cropped/train_cropped_saturation\n",
    "    - ProtoPNet/datasets/cub200_cropped/train_cropped_hue\n",
    "    - ProtoPNet/datasets/cub200_cropped/train_cropped_shape\n",
    "    - ProtoPNet/datasets/cub200_cropped/train_cropped_texture\n",
    "\t- ProtoPNet/datasets/cub200_cropped/test_cropped\n",
    "\t- ProtoPNet/datasets/cub200_cropped/test_cropped_contrast\n",
    "    - etc.\n",
    "\n",
    "Each of these folders should contain a subfolder for each class containing the images\n",
    "corresponding to this class. \n",
    "\n",
    "Then, train a ProtoPNet with main.py and the appropriate parameters in settings.py. Save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Ol8FidV4Aqx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "from preprocess import mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Jj5mItE4ArB"
   },
   "outputs": [],
   "source": [
    "# Select model to use\n",
    "load_model_dir = '../results/trained_model/'  # Model directory\n",
    "load_model_name = 'trained_model.pth'# Model name of trained ProtoPNet\n",
    "\n",
    "# Load model\n",
    "load_model_path = os.path.join(load_model_dir, load_model_name)\n",
    "epoch_number_str = re.search(r'\\d+', load_model_name).group(0)\n",
    "\n",
    "ppnet = torch.load(load_model_path)\n",
    "ppnet = ppnet.cuda()\n",
    "ppnet_multi = torch.nn.DataParallel(ppnet)\n",
    "\n",
    "# Get network properties\n",
    "img_size = ppnet_multi.module.img_size  # Image size\n",
    "prototype_shape = ppnet.prototype_shape # Prototype shape\n",
    "max_dist = prototype_shape[1] * prototype_shape[2] * prototype_shape[3]\n",
    "\n",
    "# Initialize preprocessing function used for prototypes\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize((img_size,img_size)),\n",
    "   transforms.ToTensor(),\n",
    "   transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kf8F-cEQ4ArO",
    "outputId": "422820f9-db5a-4919-d46a-696f1b3d6678"
   },
   "outputs": [],
   "source": [
    "test_dir = './datasets/cub200_cropped/train_cropped' # Path to dataset\n",
    "dataset = 'train_cropped/'\n",
    "# Names of the different kinds of modifications to use\n",
    "modifications = ['_contrast', '_saturation', '_hue', '_shape', '_texture']\n",
    "\n",
    "# Dataframe for storing results\n",
    "results = pd.DataFrame(columns=['prototype', 'modification', 'delta'])\n",
    "\n",
    "# Prototype indices (assumes 2000 prototypes for CUB-200-2011)\n",
    "prototypes = range(2000)\n",
    "\n",
    "# Loop through image files in all image folders\n",
    "for path, subdirs, files in os.walk(os.path.join(test_dir, dataset)):\n",
    "    if len(subdirs) == 0 and not \"/.ipynb_checkpoints\" in path:\n",
    "        # Loop through files in folder\n",
    "        for name in files:\n",
    "            img_path = os.path.join(path, name) # Get path of file\n",
    "            \n",
    "            img_pil = Image.open(img_path)      # Use path to open image\n",
    "            img_tensor = preprocess(img_pil)    # Apply preprocessing function, make tensor\n",
    "            img_variable = Variable(img_tensor.unsqueeze(0)) # Change type\n",
    "\n",
    "            images_test = img_variable.cuda()   # Utilize GPU\n",
    "\n",
    "            # Get network output\n",
    "            logits, min_distances = ppnet_multi(images_test)\n",
    "            ref_similarities = ppnet.distance_2_similarity(min_distances)\n",
    "\n",
    "            ref_similarities = ref_similarities[0].cpu().data.numpy()\n",
    "            \n",
    "            # Load the corresponding modified image and find difference\n",
    "            # in similarity score for each prototype with respect to a specific\n",
    "            # modification\n",
    "            for modification in modifications:\n",
    "                # Modify image path to get the modified image\n",
    "                mod_path = img_path.replace(dataset, \n",
    "                                            dataset + modification)\n",
    "                \n",
    "                # Open image and convert to RGB\n",
    "                try:\n",
    "                    img_pil = Image.open(mod_path).convert('RGB')\n",
    "                except:\n",
    "                    mod_path = mod_path + '.jpg'\n",
    "                    img_pil = Image.open(mod_path).convert('RGB')\n",
    "                \n",
    "                img_tensor = preprocess(img_pil)  # Turn image into tensor\n",
    "                img_variable = Variable(img_tensor.unsqueeze(0))  # Change type\n",
    "\n",
    "                images_test = img_variable.cuda() # Utilize GPU\n",
    "\n",
    "                # Get network output and convert to similarity scores\n",
    "                logits, min_distances = ppnet_multi(images_test)\n",
    "                mod_similarities = ppnet.distance_2_similarity(min_distances)\n",
    "\n",
    "                mod_similarities = mod_similarities[0].cpu().data.numpy() # Conversion\n",
    "                delta = -1 * (mod_similarities - ref_similarities) # Get differences (per prototype)\n",
    "\n",
    "                # Make dataframe for results (found difference)\n",
    "                df = pd.DataFrame(columns=['prototype', 'modification', 'delta'])\n",
    "                df['prototype'] = prototypes\n",
    "                df['modification'] = modification\n",
    "                df['delta'] = delta\n",
    "\n",
    "                # Put row in total results (found differences)\n",
    "                results = results.append(df, ignore_index=True)\n",
    "                \n",
    "        # Convert results dataframe to csv format and display\n",
    "        results.to_csv('prototype_scores.csv', index=False)\n",
    "        print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKyAJLAI4Aru"
   },
   "outputs": [],
   "source": [
    "# Obtain final (global) results by calculating mean over images by prototype and modification\n",
    "df_grouped = results.groupby(['prototype', 'modification']).mean()\n",
    "df_grouped.to_csv('prototype_modification_results.csv') # Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to annotate a single prototype with a specific index\n",
    "def annotate_prototype(index):\n",
    "    annotations = {\n",
    "        'Contrast': 0,\n",
    "        'Saturation': 0,\n",
    "        'Hue': 0,\n",
    "        'Shape': 0,\n",
    "        'Texture': 0\n",
    "    }\n",
    "    \n",
    "    # Load the activation differences for the prototype\n",
    "    attributes = df_grouped.loc[index]\n",
    "    \n",
    "    annotations['Contrast'] = attributes.loc['_contrast'][0]\n",
    "    annotations['Saturation'] = attributes.loc['_saturation'][0]\n",
    "    annotations['Hue'] = attributes.loc['_hue'][0]\n",
    "    annotations['Shape'] = attributes.loc['_shape'][0]\n",
    "    annotations['Texture'] = attributes.loc['_texture'][0]\n",
    "    \n",
    "    # Sort the annotations in descending order\n",
    "    annotations = {k: v for k, v in sorted(annotations.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    lower_than_zero = False\n",
    "    i = 1\n",
    "\n",
    "    print(\"Prototype \" + str(index))\n",
    "\n",
    "    # If the importance is lower than 0, leave characteristic out\n",
    "    print(\"IMPORTANT\")\n",
    "    for x in annotations.items():\n",
    "        if x[1] < 0 and not lower_than_zero:\n",
    "            print(\"\\nUNIMPORTANT\")\n",
    "            lower_than_zero = True\n",
    "\n",
    "        print(str(i) + '. ' + x[0] + '\\t (' + str(round(x[1], 5)) + ')')\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    print('\\n')\n",
    "    \n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform annotation for all prototypes in the dataset\n",
    "results = pd.DataFrame()\n",
    "for i in range(2000):\n",
    "    results = results.append(annotate_prototype(i), ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "prototype_activation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}